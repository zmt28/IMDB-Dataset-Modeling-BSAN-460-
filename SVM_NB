---
title: "BSAN 460 R Project: IMDB Movie Review Sentiment Analysis - Modeling & Analysis for Faster Feedback"
author: "Group 7: Cappy Kan, Zion Taber, Samantha Gilpin, Trang Tran"
date: "DD/MM/YYYY"
output: html_document
---
#  Loading Libraries and NLP Packages
#```{r}
install.packages("h2o")
install.packages("e1071")
install.packages("RTextTools")
library(RTextTools)
library(h2o)
library(e1071)
library(readr)
library(dplyr) # dataframe manipulation
library(tidyverse) # helps tidy data
library(tidytext)
library(tm) # text mining (text pre-processing)
library(textstem) # tools for stemming and lemmatizing text
library(wordcloud) # generates word cloud plot
library(RColorBrewer) # for color palettes used in various plots
library(syuzhet) # for sentiment scores and emotion classification
library(ggplot2) # for plotting graphs
library(pROC)# this package is used to calculate AUC (performance measure for fitness of probabilities)
library(MLmetrics)
library(caret)
options(scipen = 999) # Beta coefficients will now display as regular numbers instead of scientific notation
# during the course we may need to add additional packages for different analyses


#Importing the Dataset

getwd()
setwd("F:/BSAN 460-001/Project")
#import IMDB
imdb <- read.csv("IMDB Dataset.csv")
str(imdb)
summary(imdb)
#```

imdb$review <- gsub("<.*?>", "", imdb$review) # remove htmls/urls
imdb$review <- gsub('[[:punct:]]','', imdb$review) # remove punctuation

imdb$review <- gsub('[[:digit:]]', '', imdb$review) # remove numbers
imdb$review <- gsub(paste(stopwords('en'), collapse = '\\b|\\b'),'', imdb$review) # remove stopwords
imdb$review <- gsub('\\s+',' ', imdb$review) # remove white space
imdb$review <- lemmatize_strings(imdb$review) # lemmatize text

imdb_clean <- Corpus(VectorSource(imdb$review))

set.seed(7) # reproducable results every time we rerun the code
train_indices <- sample(nrow(imdb), size = round(.7 * nrow(imdb)), replace = F)
head(train_indices)
TrainDS <- imdb[train_indices, ]
head(TrainDS)
TestDS <- imdb[-train_indices, ]
head(test)

#Make a Wordcloud
wordcloud(imdb$review, max.words = 75)

#SVM Model
# Create the document term matrix
dtMatrix <- create_matrix(imdb["review"])

# Configure the training data
train_container <- create_container(dtMatrix, imdb$sentiment, trainSize=301:2000, virgin=FALSE)

# Configure the testing data
test_container <- create_container(dtMatrix, imdb$sentiment, testSize = 1:300, virgin=FALSE)

# train a SVM Model
model <- train_model(train_container, "SVM", kernel="linear", cost=1)

# predict
results <- classify_model(test_container, model)
results


# Creating our Naive Bayes Model
mTrain = create_matrix(TrainDS[,1], 
                       removeStopwords=FALSE, removeNumbers=FALSE, 
                       stemWords=FALSE) 
mTrain1 <- removeSparseTerms(mTrain, .95)
matTrain = as.matrix(mTrain1)

mTest = create_matrix(TestDS[,1], language="english", 
                      removeStopwords=FALSE, removeNumbers=FALSE, 
                      stemWords=FALSE) 
mTest1 <- removeSparseTerms(mTest, .95)
matTest = as.matrix(mTest1)


labelTrain = as.factor(TrainDS[,2])
labelTest = as.factor(TestDS[,2])

model = naiveBayes(matTrain, labelTrain)

# We evaluate the fitted model.
pred = predict(model, matTrain) 
confusionMatrix(labelTrain, pred)
